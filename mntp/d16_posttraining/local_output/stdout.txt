[10-25 02:53:55] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 02:53:55] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 02:53:55] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 02:54:31] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 02:54:31] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 02:54:31] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 02:54:34] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14fbb1760940>
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 02:54:34] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14fbb1760940>
[10-25 02:54:34] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 02:54:34] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 02:54:34] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 02:54:34] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.03s)
[10-25 02:54:34] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')







=======================================================   RESTART [10-25 02:55:23]   =======================================================
[10-25 02:55:23] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 02:55:23] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 02:55:23] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 02:55:26] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 02:55:26] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 02:55:26] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 02:55:28] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x147690208a60>
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 02:55:28] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x147690208a60>
[10-25 02:55:28] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 02:55:28] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 02:55:28] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 02:55:28] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 02:55:28] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')







=======================================================   RESTART [10-25 02:59:57]   =======================================================
[10-25 02:59:57] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 02:59:57] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 02:59:57] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 02:59:59] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 02:59:59] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 02:59:59] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:00:01] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x146854868a60>
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:00:01] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x146854868a60>
[10-25 03:00:01] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:00:01] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:00:01] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:00:01] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:00:01] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')







=======================================================   RESTART [10-25 03:04:03]   =======================================================
[10-25 03:04:03] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 03:04:03] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 03:04:03] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 03:04:05] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 03:04:05] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 03:04:05] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:04:07] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x148f6a4f0a60>
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:04:07] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x148f6a4f0a60>
[10-25 03:04:07] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:04:07] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:04:07] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:04:07] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:04:07] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')







=======================================================   RESTART [10-25 03:05:08]   =======================================================
[10-25 03:05:08] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 03:05:08] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 03:05:08] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 03:05:11] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 03:05:11] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 03:05:11] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:05:13] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x1484b22f8a60>
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:05:13] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x1484b22f8a60>
[10-25 03:05:13] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:05:13] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:05:13] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:05:13] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:05:13] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')







=======================================================   RESTART [10-25 03:06:59]   =======================================================
[10-25 03:06:59] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 03:06:59] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 03:06:59] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 03:07:02] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 03:07:02] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 03:07:02] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:07:04] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14ac6cdb0a60>
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:07:04] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14ac6cdb0a60>
[10-25 03:07:04] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:07:04] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:07:04] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:07:04] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:07:04] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')
[10-25 03:07:04] (zero/mntp/models/mntp.py, line 112)=> 
[constructor]  ==== flash_if_available=True (16/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [MNTP config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[10-25 03:07:04] (zero/mntp/models/mntp.py, line 135)=> torch.Size([1, 1, 680, 680])







=======================================================   RESTART [10-25 03:07:30]   =======================================================
[10-25 03:07:30] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 03:07:30] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 03:07:30] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 03:07:32] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 03:07:32] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 03:07:32] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:07:34] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14e03c2aca60>
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:07:34] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14e03c2aca60>
[10-25 03:07:34] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:07:34] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:07:34] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:07:34] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:07:34] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')
[10-25 03:07:34] (zero/mntp/models/mntp.py, line 112)=> 
[constructor]  ==== flash_if_available=True (16/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [MNTP config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[10-25 03:07:34] (zero/mntp/models/mntp.py, line 135)=> torch.Size([1, 1, 680, 680])
[10-25 03:07:34] (zero/mntp/models/mntp.py, line 340)=> [init_weights] VAR with init_std=0.0180422







=======================================================   RESTART [10-25 03:09:16]   =======================================================
[10-25 03:09:16] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 03:09:16] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 03:09:16] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 03:09:19] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 03:09:19] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 03:09:19] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:09:20] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14de645e0a60>
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:09:20] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x14de645e0a60>
[10-25 03:09:20] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:09:21] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:09:21] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:09:21] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:09:21] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')
[10-25 03:09:21] (zero/mntp/models/mntp.py, line 112)=> 
[constructor]  ==== flash_if_available=True (16/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [MNTP config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[10-25 03:09:21] (zero/mntp/models/mntp.py, line 135)=> torch.Size([1, 1, 680, 680])
[10-25 03:09:21] (zero/mntp/models/mntp.py, line 340)=> [init_weights] VAR with init_std=0.0180422
[10-25 03:09:24] (/mntp_zero/mntp/train.py, line 128)=> [INIT] VAR model = VAR(
  drop_path_rate=0.0666667
  (word_embed): Linear(in_features=32, out_features=1024, bias=True)
  (class_emb): Embedding(1001, 1024)
  (lvl_embed): TimestepEmbedder(
    (mlp): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): SiLU()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
  )
  (shared_ada_lin): Identity()
  (blocks): ModuleList(
    (0): LlamaAdaLNSelfAttn(
      shared_aln=False
      (drop_path): Identity()
      (attn): LlamaAttention(
        using_flash=True, using_xform=False, attn_l2_norm=True
        (rotary_emb): LlamaRotaryEmbedding()
        (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): LlamaMLP(
        (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
        (act_fn): SiLU()
      )
      (ln_wo_grad): RMSNorm()
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
    (1-15): 15 x LlamaAdaLNSelfAttn(
      shared_aln=False
      (drop_path): DropPath((drop_prob=...))
      (attn): LlamaAttention(
        using_flash=True, using_xform=False, attn_l2_norm=True
        (rotary_emb): LlamaRotaryEmbedding()
        (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): LlamaMLP(
        (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
        (act_fn): SiLU()
      )
      (ln_wo_grad): RMSNorm()
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
  )
  (head_nm): AdaLNBeforeHead(
    (ln_wo_grad): RMSNorm()
    (ada_lin): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
  )
  (head): Linear(in_features=1024, out_features=4096, bias=True)
  (context_pool): ContextAttentivePool(
    (ca): CrossAttention(
      Cq=1024, Ckv=1024, cos_attn=False
      (mat_kv): Linear(in_features=1024, out_features=2048, bias=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Identity()
    )
  )
  (head_context): Linear(in_features=2048, out_features=1024, bias=True)
  (norm_x): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (norm_cond): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
)


[10-25 03:09:24] (/mntp_zero/mntp/train.py, line 130)=> [INIT][#para] VAE=108.95, VAE.enc=44.11, VAE.dec=64.65, VAE.quant=0.17
[10-25 03:09:24] (/mntp_zero/mntp/train.py, line 131)=> [INIT][#para] VAR=320.27


[10-25 03:09:24] (mntp/utils/lr_control.py, line  99)=> [get_param_groups] param_groups = 
{ 'D': { 'lr_sc': 1.0,
         'params': "('word_embed.weight, class_emb.weight, blocks.0.attn.qkv_proj.weight, blocks.0.attn.proj.weight, blocks.0.ffn.gate_proj.weight, blocks.0.ffn.up_proj.weight, blocks.0.ffn.down_proj.weight, '\n"
                   " 'blocks.0.ada_lin.1.weight, blocks.1.attn.qkv_proj.weight, blocks.1.attn.proj.weight, blocks.1.ffn.gate_proj.weight, blocks.1.ffn.up_proj.weight, blocks.1.ffn.down_proj.weight, '\n"
                   " 'blocks.1.ada_lin.1.weight, blocks.2.attn.qkv_proj.weight, blocks.2.attn.proj.weight, blocks.2.ffn.gate_proj.weight, blocks.2.ffn.up_proj.weight, blocks.2.ffn.down_proj.weight, '\n"
                   " 'blocks.2.ada_lin.1.weight, blocks.3.attn.qkv_proj.weight, blocks.3.attn.proj.weight, blocks.3.ffn.gate_proj.weight, blocks.3.ffn.up_proj.weight, blocks.3.ffn.down_proj.weight, '\n"
                   " 'blocks.3.ada_lin.1.weight, blocks.4.attn.qkv_proj.weight, blocks.4.attn.proj.weight, blocks.4.ffn.gate_proj.weight, blocks.4.ffn.up_proj.weight, blocks.4.ffn.down_proj.weight, '\n"
                   " 'blocks.4.ada_lin.1.weight, blocks.5.attn.qkv_proj.weight, blocks.5.attn.proj.weight, blocks.5.ffn.gate_proj.weight, blocks.5.ffn.up_proj.weight, blocks.5.ffn.down_proj.weight, '\n"
                   " 'blocks.5.ada_lin.1.weight, blocks.6.attn.qkv_proj.weight, blocks.6.attn.proj.weight, blocks.6.ffn.gate_proj.weight, blocks.6.ffn.up_proj.weight, blocks.6.ffn.down_proj.weight, '\n"
                   " 'blocks.6.ada_lin.1.weight, blocks.7.attn.qkv_proj.weight, blocks.7.attn.proj.weight, blocks.7.ffn.gate_proj.weight, blocks.7.ffn.up_proj.weight, blocks.7.ffn.down_proj.weight, '\n"
                   " 'blocks.7.ada_lin.1.weight, blocks.8.attn.qkv_proj.weight, blocks.8.attn.proj.weight, blocks.8.ffn.gate_proj.weight, blocks.8.ffn.up_proj.weight, blocks.8.ffn.down_proj.weight, '\n"
                   " 'blocks.8.ada_lin.1.weight, blocks.9.attn.qkv_proj.weight, blocks.9.attn.proj.weight, blocks.9.ffn.gate_proj.weight, blocks.9.ffn.up_proj.weight, blocks.9.ffn.down_proj.weight, '\n"
                   " 'blocks.9.ada_lin.1.weight, blocks.10.attn.qkv_proj.weight, blocks.10.attn.proj.weight, blocks.10.ffn.gate_proj.weight, blocks.10.ffn.up_proj.weight, blocks.10.ffn.down_proj.weight, '\n"
                   " 'blocks.10.ada_lin.1.weight, blocks.11.attn.qkv_proj.weight, blocks.11.attn.proj.weight, blocks.11.ffn.gate_proj.weight, blocks.11.ffn.up_proj.weight, blocks.11.ffn.down_proj.weight, '\n"
                   " 'blocks.11.ada_lin.1.weight, blocks.12.attn.qkv_proj.weight, blocks.12.attn.proj.weight, blocks.12.ffn.gate_proj.weight, blocks.12.ffn.up_proj.weight, blocks.12.ffn.down_proj.weight, '\n"
                   " 'blocks.12.ada_lin.1.weight, blocks.13.attn.qkv_proj.weight, blocks.13.attn.proj.weight, blocks.13.ffn.gate_proj.weight, blocks.13.ffn.up_proj.weight, blocks.13.ffn.down_proj.weight, '\n"
                   " 'blocks.13.ada_lin.1.weight, blocks.14.attn.qkv_proj.weight, blocks.14.attn.proj.weight, blocks.14.ffn.gate_proj.weight, blocks.14.ffn.up_proj.weight, blocks.14.ffn.down_proj.weight, '\n"
                   " 'blocks.14.ada_lin.1.weight, blocks.15.attn.qkv_proj.weight, blocks.15.attn.proj.weight, blocks.15.ffn.gate_proj.weight, blocks.15.ffn.up_proj.weight, blocks.15.ffn.down_proj.weight, '\n"
                   " 'blocks.15.ada_lin.1.weight, head_nm.ada_lin.1.weight, head.weight, context_pool.ca.mat_q, context_pool.ca.mat_kv.weight, context_pool.ca.proj.weight, head_context.weight')",
         'wd_sc': 1.0},
  'ND': { 'lr_sc': 1.0,
          'params': "('word_embed.bias, lvl_embed.mlp.0.weight, lvl_embed.mlp.0.bias, lvl_embed.mlp.2.weight, lvl_embed.mlp.2.bias, blocks.0.attn.scale_mul_1H11, blocks.0.attn.q_bias, blocks.0.attn.v_bias, '\n"
                    " 'blocks.0.attn.proj.bias, blocks.0.ln_wo_grad.weight, blocks.0.ada_lin.1.bias, blocks.1.attn.scale_mul_1H11, blocks.1.attn.q_bias, blocks.1.attn.v_bias, blocks.1.attn.proj.bias, '\n"
                    " 'blocks.1.ln_wo_grad.weight, blocks.1.ada_lin.1.bias, blocks.2.attn.scale_mul_1H11, blocks.2.attn.q_bias, blocks.2.attn.v_bias, blocks.2.attn.proj.bias, blocks.2.ln_wo_grad.weight, '\n"
                    " 'blocks.2.ada_lin.1.bias, blocks.3.attn.scale_mul_1H11, blocks.3.attn.q_bias, blocks.3.attn.v_bias, blocks.3.attn.proj.bias, blocks.3.ln_wo_grad.weight, blocks.3.ada_lin.1.bias, '\n"
                    " 'blocks.4.attn.scale_mul_1H11, blocks.4.attn.q_bias, blocks.4.attn.v_bias, blocks.4.attn.proj.bias, blocks.4.ln_wo_grad.weight, blocks.4.ada_lin.1.bias, blocks.5.attn.scale_mul_1H11, '\n"
                    " 'blocks.5.attn.q_bias, blocks.5.attn.v_bias, blocks.5.attn.proj.bias, blocks.5.ln_wo_grad.weight, blocks.5.ada_lin.1.bias, blocks.6.attn.scale_mul_1H11, blocks.6.attn.q_bias, blocks.6.attn.v_bias, '\n"
                    " 'blocks.6.attn.proj.bias, blocks.6.ln_wo_grad.weight, blocks.6.ada_lin.1.bias, blocks.7.attn.scale_mul_1H11, blocks.7.attn.q_bias, blocks.7.attn.v_bias, blocks.7.attn.proj.bias, '\n"
                    " 'blocks.7.ln_wo_grad.weight, blocks.7.ada_lin.1.bias, blocks.8.attn.scale_mul_1H11, blocks.8.attn.q_bias, blocks.8.attn.v_bias, blocks.8.attn.proj.bias, blocks.8.ln_wo_grad.weight, '\n"
                    " 'blocks.8.ada_lin.1.bias, blocks.9.attn.scale_mul_1H11, blocks.9.attn.q_bias, blocks.9.attn.v_bias, blocks.9.attn.proj.bias, blocks.9.ln_wo_grad.weight, blocks.9.ada_lin.1.bias, '\n"
                    " 'blocks.10.attn.scale_mul_1H11, blocks.10.attn.q_bias, blocks.10.attn.v_bias, blocks.10.attn.proj.bias, blocks.10.ln_wo_grad.weight, blocks.10.ada_lin.1.bias, blocks.11.attn.scale_mul_1H11, '\n"
                    " 'blocks.11.attn.q_bias, blocks.11.attn.v_bias, blocks.11.attn.proj.bias, blocks.11.ln_wo_grad.weight, blocks.11.ada_lin.1.bias, blocks.12.attn.scale_mul_1H11, blocks.12.attn.q_bias, '\n"
                    " 'blocks.12.attn.v_bias, blocks.12.attn.proj.bias, blocks.12.ln_wo_grad.weight, blocks.12.ada_lin.1.bias, blocks.13.attn.scale_mul_1H11, blocks.13.attn.q_bias, blocks.13.attn.v_bias, '\n"
                    " 'blocks.13.attn.proj.bias, blocks.13.ln_wo_grad.weight, blocks.13.ada_lin.1.bias, blocks.14.attn.scale_mul_1H11, blocks.14.attn.q_bias, blocks.14.attn.v_bias, blocks.14.attn.proj.bias, '\n"
                    " 'blocks.14.ln_wo_grad.weight, blocks.14.ada_lin.1.bias, blocks.15.attn.scale_mul_1H11, blocks.15.attn.q_bias, blocks.15.attn.v_bias, blocks.15.attn.proj.bias, blocks.15.ln_wo_grad.weight, '\n"
                    " 'blocks.15.ada_lin.1.bias, head_nm.ln_wo_grad.weight, head_nm.ada_lin.1.bias, head.bias, context_pool.ca.v_bias, context_pool.ca.proj.bias, head_context.bias, norm_x.weight, norm_x.bias, '\n"
                    " 'norm_cond.weight, norm_cond.bias')",
          'wd_sc': 0.0}}

[10-25 03:09:24] (mntp/utils/lr_control.py, line 104)=> [get_param_groups][rank0] type(model).__name__='VAR' count=215, numel=320269568
[10-25 03:09:24] (mntp/utils/lr_control.py, line 105)=> 
[10-25 03:09:24] (/mntp_zero/mntp/train.py, line 146)=> [INIT] optim=functools.partial(<class 'torch.optim.adamw.AdamW'>, betas=(0.9, 0.95), fused=True), opt_kw={'lr': 1.5625e-05, 'weight_decay': 0}








=======================================================   RESTART [10-25 03:11:23]   =======================================================
[10-25 03:11:23] (o/mntp/utils/arg_util.py, line 173)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[10-25 03:11:23] (o/mntp/utils/arg_util.py, line 174)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[10-25 03:11:23] (o/mntp/utils/arg_util.py, line 175)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[10-25 03:11:26] (/mntp_zero/mntp/train.py, line  36)=> global bs=40, local bs=40
[10-25 03:11:26] (/mntp_zero/mntp/train.py, line  37)=> initial args:
{
  data_path           : /fs/scratch/PAS2473/MM2025/neurpis2025/dataset/ILSVRC/Data/CLS-LOC
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 1.5625e-05
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 40
  batch_size          : 40
  glb_batch_size      : 40
  ac                  : 1
  ep                  : 40
  wp                  : 0.8
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.13333333333333333
  cmd                 : --depth=16 --bs=40 --ep=40 --fp16=1 --tblr=1e-4 --alng=1e-3 --wpe=0.1 --data_load_reso=256
  branch              : main
  commit_id           : 353a6f69c20340b8411762eb72196d84074ede02
  commit_msg          : init
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output
  tb_log_dir_path     : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b40ep40adamlr0.0001wd0.05
  log_txt_path        : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/log.txt
  last_ckpt_path      : /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[10-25 03:11:26] (/mntp_zero/mntp/train.py, line  41)=> [build PT data] ...

[10-25 03:11:28] (_zero/mntp/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  48)=> Transform [train] = 
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x151741a68a60>
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:11:28] (_zero/mntp/utils/data.py, line  48)=> Transform [val] = 
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> ToTensor()
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x151741a68a60>
[10-25 03:11:28] (_zero/mntp/utils/data.py, line  54)=> ---------------------------

[10-25 03:11:28] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume] no ckpt found @ /fs/scratch/PAS2473/MM2025/CVPR2026/mntp_zero/mntp/d16_posttraining/local_output/ar-ckpt*.pth
[10-25 03:11:28] (/mntp_zero/mntp/train.py, line  64)=> [auto_resume quit]
[10-25 03:11:28] (/mntp_zero/mntp/train.py, line  65)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[10-25 03:11:28] (/mntp_zero/mntp/train.py, line  71)=> [dataloader] gbs=40, lbs=40, iters_train=32030, types(tr, va)=('DatasetFolder', 'DatasetFolder')
[10-25 03:11:28] (zero/mntp/models/mntp.py, line 112)=> 
[constructor]  ==== flash_if_available=True (16/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [MNTP config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[10-25 03:11:28] (zero/mntp/models/mntp.py, line 135)=> torch.Size([1, 1, 680, 680])
[10-25 03:11:28] (zero/mntp/models/mntp.py, line 343)=> [init_weights] VAR with init_std=0.0180422
[10-25 03:11:29] (/mntp_zero/mntp/train.py, line 128)=> [INIT] VAR model = VAR(
  drop_path_rate=0.0666667
  (word_embed): Linear(in_features=32, out_features=1024, bias=True)
  (class_emb): Embedding(1001, 1024)
  (lvl_embed): TimestepEmbedder(
    (mlp): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): SiLU()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
  )
  (shared_ada_lin): Identity()
  (blocks): ModuleList(
    (0): LlamaAdaLNSelfAttn(
      shared_aln=False
      (drop_path): Identity()
      (attn): LlamaAttention(
        using_flash=True, using_xform=False, attn_l2_norm=True
        (rotary_emb): LlamaRotaryEmbedding()
        (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): LlamaMLP(
        (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
        (act_fn): SiLU()
      )
      (ln_wo_grad): RMSNorm()
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
    (1-15): 15 x LlamaAdaLNSelfAttn(
      shared_aln=False
      (drop_path): DropPath((drop_prob=...))
      (attn): LlamaAttention(
        using_flash=True, using_xform=False, attn_l2_norm=True
        (rotary_emb): LlamaRotaryEmbedding()
        (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): LlamaMLP(
        (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (up_proj): Linear(in_features=1024, out_features=2816, bias=False)
        (down_proj): Linear(in_features=2816, out_features=1024, bias=False)
        (act_fn): SiLU()
      )
      (ln_wo_grad): RMSNorm()
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
  )
  (head_nm): AdaLNBeforeHead(
    (ln_wo_grad): RMSNorm()
    (ada_lin): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
  )
  (head): Linear(in_features=1024, out_features=4096, bias=True)
  (context_pool): ContextAttentivePool(
    (ca): CrossAttention(
      Cq=1024, Ckv=1024, cos_attn=False
      (mat_kv): Linear(in_features=1024, out_features=2048, bias=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Identity()
    )
  )
  (head_context): Linear(in_features=2048, out_features=1024, bias=True)
  (norm_x): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (norm_cond): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
)


[10-25 03:11:29] (/mntp_zero/mntp/train.py, line 130)=> [INIT][#para] VAE=108.95, VAE.enc=44.11, VAE.dec=64.65, VAE.quant=0.17
[10-25 03:11:29] (/mntp_zero/mntp/train.py, line 131)=> [INIT][#para] VAR=320.27


[10-25 03:11:29] (mntp/utils/lr_control.py, line  99)=> [get_param_groups] param_groups = 
{ 'D': { 'lr_sc': 1.0,
         'params': "('word_embed.weight, class_emb.weight, blocks.0.attn.qkv_proj.weight, blocks.0.attn.proj.weight, blocks.0.ffn.gate_proj.weight, blocks.0.ffn.up_proj.weight, blocks.0.ffn.down_proj.weight, '\n"
                   " 'blocks.0.ada_lin.1.weight, blocks.1.attn.qkv_proj.weight, blocks.1.attn.proj.weight, blocks.1.ffn.gate_proj.weight, blocks.1.ffn.up_proj.weight, blocks.1.ffn.down_proj.weight, '\n"
                   " 'blocks.1.ada_lin.1.weight, blocks.2.attn.qkv_proj.weight, blocks.2.attn.proj.weight, blocks.2.ffn.gate_proj.weight, blocks.2.ffn.up_proj.weight, blocks.2.ffn.down_proj.weight, '\n"
                   " 'blocks.2.ada_lin.1.weight, blocks.3.attn.qkv_proj.weight, blocks.3.attn.proj.weight, blocks.3.ffn.gate_proj.weight, blocks.3.ffn.up_proj.weight, blocks.3.ffn.down_proj.weight, '\n"
                   " 'blocks.3.ada_lin.1.weight, blocks.4.attn.qkv_proj.weight, blocks.4.attn.proj.weight, blocks.4.ffn.gate_proj.weight, blocks.4.ffn.up_proj.weight, blocks.4.ffn.down_proj.weight, '\n"
                   " 'blocks.4.ada_lin.1.weight, blocks.5.attn.qkv_proj.weight, blocks.5.attn.proj.weight, blocks.5.ffn.gate_proj.weight, blocks.5.ffn.up_proj.weight, blocks.5.ffn.down_proj.weight, '\n"
                   " 'blocks.5.ada_lin.1.weight, blocks.6.attn.qkv_proj.weight, blocks.6.attn.proj.weight, blocks.6.ffn.gate_proj.weight, blocks.6.ffn.up_proj.weight, blocks.6.ffn.down_proj.weight, '\n"
                   " 'blocks.6.ada_lin.1.weight, blocks.7.attn.qkv_proj.weight, blocks.7.attn.proj.weight, blocks.7.ffn.gate_proj.weight, blocks.7.ffn.up_proj.weight, blocks.7.ffn.down_proj.weight, '\n"
                   " 'blocks.7.ada_lin.1.weight, blocks.8.attn.qkv_proj.weight, blocks.8.attn.proj.weight, blocks.8.ffn.gate_proj.weight, blocks.8.ffn.up_proj.weight, blocks.8.ffn.down_proj.weight, '\n"
                   " 'blocks.8.ada_lin.1.weight, blocks.9.attn.qkv_proj.weight, blocks.9.attn.proj.weight, blocks.9.ffn.gate_proj.weight, blocks.9.ffn.up_proj.weight, blocks.9.ffn.down_proj.weight, '\n"
                   " 'blocks.9.ada_lin.1.weight, blocks.10.attn.qkv_proj.weight, blocks.10.attn.proj.weight, blocks.10.ffn.gate_proj.weight, blocks.10.ffn.up_proj.weight, blocks.10.ffn.down_proj.weight, '\n"
                   " 'blocks.10.ada_lin.1.weight, blocks.11.attn.qkv_proj.weight, blocks.11.attn.proj.weight, blocks.11.ffn.gate_proj.weight, blocks.11.ffn.up_proj.weight, blocks.11.ffn.down_proj.weight, '\n"
                   " 'blocks.11.ada_lin.1.weight, blocks.12.attn.qkv_proj.weight, blocks.12.attn.proj.weight, blocks.12.ffn.gate_proj.weight, blocks.12.ffn.up_proj.weight, blocks.12.ffn.down_proj.weight, '\n"
                   " 'blocks.12.ada_lin.1.weight, blocks.13.attn.qkv_proj.weight, blocks.13.attn.proj.weight, blocks.13.ffn.gate_proj.weight, blocks.13.ffn.up_proj.weight, blocks.13.ffn.down_proj.weight, '\n"
                   " 'blocks.13.ada_lin.1.weight, blocks.14.attn.qkv_proj.weight, blocks.14.attn.proj.weight, blocks.14.ffn.gate_proj.weight, blocks.14.ffn.up_proj.weight, blocks.14.ffn.down_proj.weight, '\n"
                   " 'blocks.14.ada_lin.1.weight, blocks.15.attn.qkv_proj.weight, blocks.15.attn.proj.weight, blocks.15.ffn.gate_proj.weight, blocks.15.ffn.up_proj.weight, blocks.15.ffn.down_proj.weight, '\n"
                   " 'blocks.15.ada_lin.1.weight, head_nm.ada_lin.1.weight, head.weight, context_pool.ca.mat_q, context_pool.ca.mat_kv.weight, context_pool.ca.proj.weight, head_context.weight')",
         'wd_sc': 1.0},
  'ND': { 'lr_sc': 1.0,
          'params': "('word_embed.bias, lvl_embed.mlp.0.weight, lvl_embed.mlp.0.bias, lvl_embed.mlp.2.weight, lvl_embed.mlp.2.bias, blocks.0.attn.scale_mul_1H11, blocks.0.attn.q_bias, blocks.0.attn.v_bias, '\n"
                    " 'blocks.0.attn.proj.bias, blocks.0.ln_wo_grad.weight, blocks.0.ada_lin.1.bias, blocks.1.attn.scale_mul_1H11, blocks.1.attn.q_bias, blocks.1.attn.v_bias, blocks.1.attn.proj.bias, '\n"
                    " 'blocks.1.ln_wo_grad.weight, blocks.1.ada_lin.1.bias, blocks.2.attn.scale_mul_1H11, blocks.2.attn.q_bias, blocks.2.attn.v_bias, blocks.2.attn.proj.bias, blocks.2.ln_wo_grad.weight, '\n"
                    " 'blocks.2.ada_lin.1.bias, blocks.3.attn.scale_mul_1H11, blocks.3.attn.q_bias, blocks.3.attn.v_bias, blocks.3.attn.proj.bias, blocks.3.ln_wo_grad.weight, blocks.3.ada_lin.1.bias, '\n"
                    " 'blocks.4.attn.scale_mul_1H11, blocks.4.attn.q_bias, blocks.4.attn.v_bias, blocks.4.attn.proj.bias, blocks.4.ln_wo_grad.weight, blocks.4.ada_lin.1.bias, blocks.5.attn.scale_mul_1H11, '\n"
                    " 'blocks.5.attn.q_bias, blocks.5.attn.v_bias, blocks.5.attn.proj.bias, blocks.5.ln_wo_grad.weight, blocks.5.ada_lin.1.bias, blocks.6.attn.scale_mul_1H11, blocks.6.attn.q_bias, blocks.6.attn.v_bias, '\n"
                    " 'blocks.6.attn.proj.bias, blocks.6.ln_wo_grad.weight, blocks.6.ada_lin.1.bias, blocks.7.attn.scale_mul_1H11, blocks.7.attn.q_bias, blocks.7.attn.v_bias, blocks.7.attn.proj.bias, '\n"
                    " 'blocks.7.ln_wo_grad.weight, blocks.7.ada_lin.1.bias, blocks.8.attn.scale_mul_1H11, blocks.8.attn.q_bias, blocks.8.attn.v_bias, blocks.8.attn.proj.bias, blocks.8.ln_wo_grad.weight, '\n"
                    " 'blocks.8.ada_lin.1.bias, blocks.9.attn.scale_mul_1H11, blocks.9.attn.q_bias, blocks.9.attn.v_bias, blocks.9.attn.proj.bias, blocks.9.ln_wo_grad.weight, blocks.9.ada_lin.1.bias, '\n"
                    " 'blocks.10.attn.scale_mul_1H11, blocks.10.attn.q_bias, blocks.10.attn.v_bias, blocks.10.attn.proj.bias, blocks.10.ln_wo_grad.weight, blocks.10.ada_lin.1.bias, blocks.11.attn.scale_mul_1H11, '\n"
                    " 'blocks.11.attn.q_bias, blocks.11.attn.v_bias, blocks.11.attn.proj.bias, blocks.11.ln_wo_grad.weight, blocks.11.ada_lin.1.bias, blocks.12.attn.scale_mul_1H11, blocks.12.attn.q_bias, '\n"
                    " 'blocks.12.attn.v_bias, blocks.12.attn.proj.bias, blocks.12.ln_wo_grad.weight, blocks.12.ada_lin.1.bias, blocks.13.attn.scale_mul_1H11, blocks.13.attn.q_bias, blocks.13.attn.v_bias, '\n"
                    " 'blocks.13.attn.proj.bias, blocks.13.ln_wo_grad.weight, blocks.13.ada_lin.1.bias, blocks.14.attn.scale_mul_1H11, blocks.14.attn.q_bias, blocks.14.attn.v_bias, blocks.14.attn.proj.bias, '\n"
                    " 'blocks.14.ln_wo_grad.weight, blocks.14.ada_lin.1.bias, blocks.15.attn.scale_mul_1H11, blocks.15.attn.q_bias, blocks.15.attn.v_bias, blocks.15.attn.proj.bias, blocks.15.ln_wo_grad.weight, '\n"
                    " 'blocks.15.ada_lin.1.bias, head_nm.ln_wo_grad.weight, head_nm.ada_lin.1.bias, head.bias, context_pool.ca.v_bias, context_pool.ca.proj.bias, head_context.bias, norm_x.weight, norm_x.bias, '\n"
                    " 'norm_cond.weight, norm_cond.bias')",
          'wd_sc': 0.0}}

[10-25 03:11:29] (mntp/utils/lr_control.py, line 104)=> [get_param_groups][rank0] type(model).__name__='VAR' count=215, numel=320269568
[10-25 03:11:29] (mntp/utils/lr_control.py, line 105)=> 
[10-25 03:11:29] (/mntp_zero/mntp/train.py, line 146)=> [INIT] optim=functools.partial(<class 'torch.optim.adamw.AdamW'>, betas=(0.9, 0.95), fused=True), opt_kw={'lr': 1.5625e-05, 'weight_decay': 0}

[10-25 03:11:33] (_zero/mntp/utils/misc.py, line 314)=> [Ep]: [   0/40]  [    0/32030]  eta: 1 day, 15:17:48  tlr: 7.8e-08  tnm: 0.22  Lm: 8.318 (8.318)  Lt: 8.318 (8.318)  Accm: 0.02 (0.02)  Acct: 0.03 (0.03)  time: 4.4168  data: 0.2190
